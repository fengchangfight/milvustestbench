{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Search with Milvus\n",
    "\n",
    "This notebook demonstrates how to perform image similarity search using Milvus vector database. It uses a pre-trained ResNet model to extract image features and stores them in Milvus for efficient similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.preprocessing import normalize\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from pymilvus import MilvusClient\n",
    "import os\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor Class\n",
    "\n",
    "This class handles the extraction of image features using a pre-trained model from the TIMM library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, modelname):\n",
    "        # Load the pre-trained model\n",
    "        self.model = timm.create_model(\n",
    "            modelname, pretrained=True, num_classes=0, global_pool=\"avg\"\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "        # Get the input size required by the model\n",
    "        self.input_size = self.model.default_cfg[\"input_size\"]\n",
    "\n",
    "        config = resolve_data_config({}, model=modelname)\n",
    "        # Get the preprocessing function provided by TIMM for the model\n",
    "        self.preprocess = create_transform(**config)\n",
    "\n",
    "    def __call__(self, imagepath):\n",
    "        # Preprocess the input image\n",
    "        input_image = Image.open(imagepath).convert(\"RGB\")  # Convert to RGB if needed\n",
    "        input_image = self.preprocess(input_image)\n",
    "\n",
    "        # Convert the image to a PyTorch tensor and add a batch dimension\n",
    "        input_tensor = input_image.unsqueeze(0)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "\n",
    "        # Extract the feature vector\n",
    "        feature_vector = output.squeeze().numpy()\n",
    "\n",
    "        return normalize(feature_vector.reshape(1, -1), norm=\"l2\").flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milvus Setup\n",
    "\n",
    "Connect to Milvus and create a collection for storing image embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus collection 'image_embeddings' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Connect to Milvus\n",
    "client = MilvusClient(\n",
    "    uri=\"http://localhost:19530\",\n",
    "    token=\"root:Milvus\"\n",
    ")\n",
    "\n",
    "# Drop existing collection if it exists\n",
    "if client.has_collection(collection_name=\"image_embeddings\"):\n",
    "    client.drop_collection(collection_name=\"image_embeddings\")\n",
    "\n",
    "# Create new collection\n",
    "client.create_collection(\n",
    "    collection_name=\"image_embeddings\",\n",
    "    vector_field_name=\"vector\",\n",
    "    dimension=512,\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    "    metric_type=\"COSINE\",\n",
    ")\n",
    "\n",
    "print(\"Milvus collection 'image_embeddings' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feature Extractor\n",
    "\n",
    "Create an instance of the FeatureExtractor using ResNet34 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13920f6462c4ba5a5ca4c6a0538ccec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extractor initialized with ResNet34 model\n"
     ]
    }
   ],
   "source": [
    "# Initialize the feature extractor with ResNet34\n",
    "extractor = FeatureExtractor(\"resnet34\")\n",
    "print(\"Feature extractor initialized with ResNet34 model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "Process images from the training directory and insert their embeddings into Milvus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 images...\n",
      "Processed 200 images...\n",
      "Processed 300 images...\n",
      "Processed 400 images...\n",
      "Processed 500 images...\n",
      "Processed 600 images...\n",
      "Processed 700 images...\n",
      "Processed 800 images...\n",
      "Processed 900 images...\n",
      "Processed 1000 images...\n",
      "Total images processed: 1000\n",
      "Data ingestion completed!\n"
     ]
    }
   ],
   "source": [
    "# Process and insert images\n",
    "root = \"data/train\"\n",
    "insert = True\n",
    "\n",
    "if insert is True:\n",
    "    processed_count = 0\n",
    "    for dirpath, foldername, filenames in os.walk(root):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".JPEG\"):\n",
    "                filepath = dirpath + \"/\" + filename\n",
    "                image_embedding = extractor(filepath)\n",
    "                client.insert(\n",
    "                    \"image_embeddings\",\n",
    "                    {\"vector\": image_embedding, \"filename\": filepath},\n",
    "                )\n",
    "                processed_count += 1\n",
    "                if processed_count % 100 == 0:\n",
    "                    print(f\"Processed {processed_count} images...\")\n",
    "    \n",
    "    print(f\"Total images processed: {processed_count}\")\n",
    "    print(\"Data ingestion completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Search\n",
    "\n",
    "Perform similarity search using a query image and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define query image\n",
    "query_image = \"data/test/Afghan_hound/n02088094_4261.JPEG\"\n",
    "\n",
    "# Perform search\n",
    "results = client.search(\n",
    "    \"image_embeddings\",\n",
    "    data=[extractor(query_image)],\n",
    "    output_fields=[\"filename\"],\n",
    "    search_params={\"metric_type\": \"COSINE\"},\n",
    ")\n",
    "\n",
    "print(\"Search completed!\")\n",
    "print(f\"Found {len(results[0])} similar images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results\n",
    "\n",
    "Visualize the query image and the top similar images found by the search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare images for display\n",
    "images = []\n",
    "for result in results:\n",
    "    for hit in result[:10]:  # Get top 10 results\n",
    "        filename = hit[\"entity\"][\"filename\"]\n",
    "        img = Image.open(filename)\n",
    "        img = img.resize((150, 150))\n",
    "        images.append(img)\n",
    "\n",
    "# Create a grid of images\n",
    "width = 150 * 5\n",
    "height = 150 * 2\n",
    "concatenated_image = Image.new(\"RGB\", (width, height))\n",
    "\n",
    "for idx, img in enumerate(images):\n",
    "    x = idx % 5\n",
    "    y = idx // 5\n",
    "    concatenated_image.paste(img, (x * 150, y * 150))\n",
    "\n",
    "# Display the query image and results\n",
    "print(\"Query Image:\")\n",
    "display(Image.open(query_image).resize((150, 150)))\n",
    "\n",
    "print(\"\\nTop 10 Similar Images:\")\n",
    "display(concatenated_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
